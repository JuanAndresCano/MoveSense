{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIXXP-TaNol1"
      },
      "source": [
        "# Exploración de datos con MediaPipe Pose\n",
        "\n",
        "Este cuaderno realiza una exploración inicial sobre videos con actividades humanas usando extracción de pose (landmarks) con MediaPipe.\n",
        "\n",
        "## Objetivos\n",
        "- Cargar un video de ejemplo (subido o por ruta en Colab).\n",
        "- Extraer landmarks de pose (hombros, caderas, rodillas, tobillos, muñecas, cabeza).\n",
        "- Preprocesar: normalización por tamaño de torso y suavizado.\n",
        "- Generar características: ángulos de rodilla y cadera, inclinación de tronco, velocidades.\n",
        "- Visualizar series temporales y estadísticas básicas.\n",
        "- Integrar anotaciones si se proporciona un CSV y analizar distribución por clases.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUHeAHg_Nol3",
        "outputId": "b3783457-12bb-4a72-97a9-d99a150b433b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'numpy': '2.0.2', 'pandas': '2.2.2', 'cv2': '4.12.0', 'mediapipe': '0.10.14', 'matplotlib': '3.10.0', 'scipy': '1.16.3', 'seaborn': '0.13.2'}\n"
          ]
        }
      ],
      "source": [
        "# Instalación de dependencias (si es necesario) y paquetes\n",
        "import sys, subprocess, importlib\n",
        "\n",
        "def ensure(pkg, import_name=None, version=None):\n",
        "    try:\n",
        "        return importlib.import_module(import_name or pkg)\n",
        "    except Exception:\n",
        "        to_install = pkg if version is None else f\"{pkg}=={version}\"\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", to_install])\n",
        "        return importlib.import_module(import_name or pkg)\n",
        "\n",
        "np = ensure(\"numpy\")\n",
        "pd = ensure(\"pandas\")\n",
        "cv2 = ensure(\"opencv-python\", \"cv2\")\n",
        "mp = ensure(\"mediapipe\", \"mediapipe\", version=\"0.10.14\")\n",
        "matplotlib = ensure(\"matplotlib\")\n",
        "plt = importlib.import_module(\"matplotlib.pyplot\")\n",
        "scipy = ensure(\"scipy\")\n",
        "from scipy.signal import savgol_filter\n",
        "try:\n",
        "    sns = ensure(\"seaborn\")\n",
        "except Exception:\n",
        "    sns = None\n",
        "\n",
        "print({\n",
        "    \"numpy\": np.__version__,\n",
        "    \"pandas\": pd.__version__,\n",
        "    \"cv2\": cv2.__version__,\n",
        "    \"mediapipe\": mp.__version__,\n",
        "    \"matplotlib\": matplotlib.__version__,\n",
        "    \"scipy\": scipy.__version__,\n",
        "    \"seaborn\": getattr(sns, \"__version__\", \"not-installed\"),\n",
        "})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDoVPGAtNol4"
      },
      "outputs": [],
      "source": [
        "# Entrada: ruta de video y (opcional) anotaciones (Colab)\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "from google.colab import files  # type: ignore\n",
        "\n",
        "# Opcional: define una ruta si ya tienes el archivo en el entorno de Colab\n",
        "VIDEO_PATH: str = \"\"  # p.ej., \"/content/mi_video.mp4\"\n",
        "ANNOTATIONS_CSV: str = \"\"  # p.ej., \"/content/anotaciones.csv\"\n",
        "\n",
        "EXPECTED_ANNOTATION_FORMAT = \"either-intervals-or-framewise\"\n",
        "# Formatos soportados:\n",
        "# - Intervalos: columnas [start_s, end_s, label]\n",
        "# - Framewise: columnas [frame, label]\n",
        "\n",
        "\n",
        "def choose_video_path() -> str:\n",
        "    if VIDEO_PATH:\n",
        "        p = Path(VIDEO_PATH)\n",
        "        if p.exists():\n",
        "            return str(p)\n",
        "        else:\n",
        "            print(f\"No se encontró VIDEO_PATH: {VIDEO_PATH}. Se solicitará subida.\")\n",
        "    print(\"Sube un archivo de video (mp4/mov/avi)...\")\n",
        "    uploaded = files.upload()\n",
        "    assert uploaded, \"Debes subir un archivo de video.\"\n",
        "    path = list(uploaded.keys())[0]\n",
        "    print(f\"Video subido: {path}\")\n",
        "    return path\n",
        "\n",
        "video_path = choose_video_path()\n",
        "print(\"Usando video:\", video_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGuptPAjNol4"
      },
      "outputs": [],
      "source": [
        "# Extracción de pose con MediaPipe\n",
        "from dataclasses import dataclass\n",
        "import math\n",
        "\n",
        "POSE_LM = mp.solutions.pose.PoseLandmark\n",
        "SELECTED_LANDMARKS = [\n",
        "    POSE_LM.NOSE,\n",
        "    POSE_LM.LEFT_SHOULDER, POSE_LM.RIGHT_SHOULDER,\n",
        "    POSE_LM.LEFT_HIP, POSE_LM.RIGHT_HIP,\n",
        "    POSE_LM.LEFT_KNEE, POSE_LM.RIGHT_KNEE,\n",
        "    POSE_LM.LEFT_ANKLE, POSE_LM.RIGHT_ANKLE,\n",
        "    POSE_LM.LEFT_WRIST, POSE_LM.RIGHT_WRIST,\n",
        "]\n",
        "\n",
        "@dataclass\n",
        "class VideoInfo:\n",
        "    fps: float\n",
        "    width: int\n",
        "    height: int\n",
        "    frame_count: int\n",
        "    duration_s: float\n",
        "\n",
        "\n",
        "def read_video_info(path: str) -> VideoInfo:\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    assert cap.isOpened(), f\"No se pudo abrir el video: {path}\"\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    duration_s = frame_count / fps if fps > 0 else 0.0\n",
        "    cap.release()\n",
        "    return VideoInfo(fps=fps, width=width, height=height, frame_count=frame_count, duration_s=duration_s)\n",
        "\n",
        "\n",
        "def extract_pose_dataframe(path: str, sample_every_n: int = 1) -> tuple[pd.DataFrame, VideoInfo]:\n",
        "    info = read_video_info(path)\n",
        "    records = []\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    with mp.solutions.pose.Pose(\n",
        "        static_image_mode=False,\n",
        "        model_complexity=1,\n",
        "        enable_segmentation=False,\n",
        "        min_detection_confidence=0.5,\n",
        "        min_tracking_confidence=0.5,\n",
        "    ) as pose:\n",
        "        frame_idx = 0\n",
        "        while cap.isOpened():\n",
        "            ok, frame_bgr = cap.read()\n",
        "            if not ok:\n",
        "                break\n",
        "            if frame_idx % sample_every_n != 0:\n",
        "                frame_idx += 1\n",
        "                continue\n",
        "            frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
        "            res = pose.process(frame_rgb)\n",
        "            time_s = frame_idx / (info.fps if info.fps > 0 else 30.0)\n",
        "            if res.pose_landmarks:\n",
        "                lm = res.pose_landmarks.landmark\n",
        "                # Puntos medios para torso\n",
        "                l_sh = lm[POSE_LM.LEFT_SHOULDER.value]\n",
        "                r_sh = lm[POSE_LM.RIGHT_SHOULDER.value]\n",
        "                l_hip = lm[POSE_LM.LEFT_HIP.value]\n",
        "                r_hip = lm[POSE_LM.RIGHT_HIP.value]\n",
        "                shoulder_mid = ((l_sh.x + r_sh.x) / 2.0, (l_sh.y + r_sh.y) / 2.0)\n",
        "                hip_mid = ((l_hip.x + r_hip.x) / 2.0, (l_hip.y + r_hip.y) / 2.0)\n",
        "                torso_size = math.hypot(shoulder_mid[0] - hip_mid[0], shoulder_mid[1] - hip_mid[1])\n",
        "                torso_size = torso_size if torso_size > 1e-6 else 1.0\n",
        "\n",
        "                row = {\n",
        "                    \"frame\": frame_idx,\n",
        "                    \"time_s\": time_s,\n",
        "                }\n",
        "                # Guardar coords normalizadas relativas al centro de cadera y escaladas por tamaño de torso\n",
        "                for landmark in SELECTED_LANDMARKS:\n",
        "                    p = lm[landmark.value]\n",
        "                    rel_x = (p.x - hip_mid[0]) / torso_size\n",
        "                    rel_y = (p.y - hip_mid[1]) / torso_size\n",
        "                    row[f\"{landmark.name.lower()}_x\"] = rel_x\n",
        "                    row[f\"{landmark.name.lower()}_y\"] = rel_y\n",
        "                    row[f\"{landmark.name.lower()}_v\"] = p.visibility\n",
        "                # guardar puntos medios\n",
        "                row[\"shoulder_mid_x\"], row[\"shoulder_mid_y\"] = (\n",
        "                    (shoulder_mid[0] - hip_mid[0]) / torso_size,\n",
        "                    (shoulder_mid[1] - hip_mid[1]) / torso_size,\n",
        "                )\n",
        "                row[\"hip_mid_x\"], row[\"hip_mid_y\"] = 0.0, 0.0\n",
        "                records.append(row)\n",
        "            frame_idx += 1\n",
        "    cap.release()\n",
        "    df = pd.DataFrame.from_records(records)\n",
        "    return df, info\n",
        "\n",
        "pose_df, video_info = extract_pose_dataframe(video_path)\n",
        "print(video_info)\n",
        "print(\"Frames con pose detectada:\", len(pose_df))\n",
        "pose_df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxfgoCZENol5"
      },
      "outputs": [],
      "source": [
        "# Preprocesamiento: suavizado y utilidades geométricas\n",
        "\n",
        "def smooth_series(y: np.ndarray, window: int = 11, poly: int = 2) -> np.ndarray:\n",
        "    if y.ndim == 1:\n",
        "        n = len(y)\n",
        "    else:\n",
        "        n = y.shape[0]\n",
        "    if n < 5:\n",
        "        return y\n",
        "    w = min(window, n - (1 - n % 2))\n",
        "    if w % 2 == 0:\n",
        "        w = max(3, w - 1)\n",
        "    try:\n",
        "        return savgol_filter(y, window_length=w, polyorder=min(poly, w - 1), axis=0)\n",
        "    except Exception:\n",
        "        return y\n",
        "\n",
        "\n",
        "def angle_between(v1: np.ndarray, v2: np.ndarray, eps: float = 1e-8) -> float:\n",
        "    a = v1 / (np.linalg.norm(v1) + eps)\n",
        "    b = v2 / (np.linalg.norm(v2) + eps)\n",
        "    cosang = np.clip(np.dot(a, b), -1.0, 1.0)\n",
        "    return float(np.degrees(np.arccos(cosang)))\n",
        "\n",
        "\n",
        "def get_xy(df: pd.DataFrame, base: str) -> tuple[np.ndarray, np.ndarray]:\n",
        "    return df[f\"{base}_x\"].to_numpy(), df[f\"{base}_y\"].to_numpy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqSJnlCbNol5"
      },
      "outputs": [],
      "source": [
        "# Extracción de características: ángulos, inclinación, velocidades\n",
        "\n",
        "def compute_features(df: pd.DataFrame, fps: float) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    # Puntos medios tronco\n",
        "    shoulder = out[[\"shoulder_mid_x\", \"shoulder_mid_y\"]].to_numpy()\n",
        "    hip = out[[\"hip_mid_x\", \"hip_mid_y\"]].to_numpy()\n",
        "    trunk_vec = shoulder - hip\n",
        "    # Inclinación del tronco respecto al eje vertical (0, -1)\n",
        "    vertical = np.stack([np.zeros(len(out)), -np.ones(len(out))], axis=1)\n",
        "    trunk_incl_deg = np.array([angle_between(trunk_vec[i], vertical[i]) for i in range(len(out))])\n",
        "    out[\"trunk_incl_deg_raw\"] = trunk_incl_deg\n",
        "    out[\"trunk_incl_deg\"] = smooth_series(trunk_incl_deg)\n",
        "\n",
        "    # Ángulos de rodilla: entre (cadera->rodilla) y (tobillo->rodilla)\n",
        "    def joint_angle(prox_base: str, joint: str, dist_base: str) -> np.ndarray:\n",
        "        px = out[[f\"{prox_base}_x\", f\"{prox_base}_y\"]].to_numpy()\n",
        "        jx = out[[f\"{joint}_x\", f\"{joint}_y\"]].to_numpy()\n",
        "        dx = out[[f\"{dist_base}_x\", f\"{dist_base}_y\"]].to_numpy()\n",
        "        v1 = px - jx\n",
        "        v2 = dx - jx\n",
        "        return np.array([angle_between(v1[i], v2[i]) for i in range(len(out))])\n",
        "\n",
        "    lknee_deg = joint_angle(\"left_hip\", \"left_knee\", \"left_ankle\")\n",
        "    rknee_deg = joint_angle(\"right_hip\", \"right_knee\", \"right_ankle\")\n",
        "    out[\"left_knee_deg_raw\"], out[\"right_knee_deg_raw\"] = lknee_deg, rknee_deg\n",
        "    out[\"left_knee_deg\"], out[\"right_knee_deg\"] = smooth_series(lknee_deg), smooth_series(rknee_deg)\n",
        "\n",
        "    # Ángulo de cadera: entre (hombro_mid->cadera) y (rodilla->cadera)\n",
        "    def hip_angle(side: str) -> np.ndarray:\n",
        "        shoulder_mid = out[[\"shoulder_mid_x\", \"shoulder_mid_y\"]].to_numpy()\n",
        "        hip_pt = out[[f\"{side}_hip_x\", f\"{side}_hip_y\"]].to_numpy()\n",
        "        knee_pt = out[[f\"{side}_knee_x\", f\"{side}_knee_y\"]].to_numpy()\n",
        "        v1 = shoulder_mid - hip_pt\n",
        "        v2 = knee_pt - hip_pt\n",
        "        return np.array([angle_between(v1[i], v2[i]) for i in range(len(out))])\n",
        "\n",
        "    lhip_deg = hip_angle(\"left\")\n",
        "    rhip_deg = hip_angle(\"right\")\n",
        "    out[\"left_hip_deg_raw\"], out[\"right_hip_deg_raw\"] = lhip_deg, rhip_deg\n",
        "    out[\"left_hip_deg\"], out[\"right_hip_deg\"] = smooth_series(lhip_deg), smooth_series(rhip_deg)\n",
        "\n",
        "    # Velocidades (derivadas) para algunos puntos clave\n",
        "    def deriv(a: np.ndarray, fps: float) -> np.ndarray:\n",
        "        if len(a) < 2:\n",
        "            return np.zeros_like(a)\n",
        "        d = np.gradient(a, 1.0 / max(fps, 1.0), axis=0)\n",
        "        return d\n",
        "\n",
        "    for base in [\n",
        "        \"left_wrist\", \"right_wrist\",\n",
        "        \"left_knee\", \"right_knee\",\n",
        "        \"left_ankle\", \"right_ankle\",\n",
        "    ]:\n",
        "        x, y = get_xy(out, base)\n",
        "        vx, vy = deriv(x, fps), deriv(y, fps)\n",
        "        speed = np.sqrt(vx**2 + vy**2)\n",
        "        out[f\"{base}_speed\"] = smooth_series(speed)\n",
        "\n",
        "    return out\n",
        "\n",
        "features_df = compute_features(pose_df, fps=max(video_info.fps, 1.0))\n",
        "features_df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k41G9OKbNol5"
      },
      "outputs": [],
      "source": [
        "# EDA: estadísticas y visualizaciones\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(features_df[\"time_s\"], features_df[\"left_knee_deg\"], label=\"Left knee\")\n",
        "plt.plot(features_df[\"time_s\"], features_df[\"right_knee_deg\"], label=\"Right knee\")\n",
        "plt.title(\"Ángulo de rodilla (suavizado)\")\n",
        "plt.xlabel(\"Tiempo (s)\")\n",
        "plt.ylabel(\"Grados\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(features_df[\"time_s\"], features_df[\"left_hip_deg\"], label=\"Left hip\")\n",
        "plt.plot(features_df[\"time_s\"], features_df[\"right_hip_deg\"], label=\"Right hip\")\n",
        "plt.title(\"Ángulo de cadera (suavizado)\")\n",
        "plt.xlabel(\"Tiempo (s)\")\n",
        "plt.ylabel(\"Grados\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(features_df[\"time_s\"], features_df[\"trunk_incl_deg\"], color=\"tab:orange\")\n",
        "plt.title(\"Inclinación del tronco (grados)\")\n",
        "plt.xlabel(\"Tiempo (s)\")\n",
        "plt.ylabel(\"Grados\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "summary_cols = [\n",
        "    \"left_knee_deg\", \"right_knee_deg\",\n",
        "    \"left_hip_deg\", \"right_hip_deg\",\n",
        "    \"trunk_incl_deg\",\n",
        "    \"left_wrist_speed\", \"right_wrist_speed\",\n",
        "    \"left_knee_speed\", \"right_knee_speed\",\n",
        "    \"left_ankle_speed\", \"right_ankle_speed\",\n",
        "]\n",
        "print(\"Resumen estadístico de características clave:\")\n",
        "display(features_df[summary_cols].describe().T)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnNFFzzKNol6"
      },
      "outputs": [],
      "source": [
        "# (Opcional) Cargar anotaciones y analizar distribución por clases\n",
        "import pandas as pd\n",
        "from typing import Optional\n",
        "\n",
        "\n",
        "def load_annotations(csv_path: str) -> Optional[pd.DataFrame]:\n",
        "    if not csv_path:\n",
        "        print(\"No se proporcionó ANNOTATIONS_CSV. Saltando.\")\n",
        "        return None\n",
        "    p = Path(csv_path)\n",
        "    if not p.exists():\n",
        "        print(f\"No existe el archivo de anotaciones: {csv_path}\")\n",
        "        return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(\"Anotaciones cargadas:\", df.shape)\n",
        "    return df\n",
        "\n",
        "\n",
        "def align_annotations_per_frame(ann: pd.DataFrame, fps: float, frames: int) -> Optional[pd.Series]:\n",
        "    # Soporta dos formatos: intervalos o por frame\n",
        "    cols = set(c.lower() for c in ann.columns)\n",
        "    labels = pd.Series([None] * frames, name=\"label\")\n",
        "    if {\"start_s\", \"end_s\", \"label\"}.issubset(cols):\n",
        "        for _, row in ann.iterrows():\n",
        "            s = int(max(0, round(row[\"start_s\"] * fps)))\n",
        "            e = int(min(frames - 1, round(row[\"end_s\"] * fps)))\n",
        "            labels.iloc[s : e + 1] = row[\"label\"]\n",
        "        return labels\n",
        "    if {\"frame\", \"label\"}.issubset(cols):\n",
        "        idx = ann[\"frame\"].astype(int).clip(0, frames - 1)\n",
        "        labels.iloc[idx] = ann[\"label\"].astype(str)\n",
        "        return labels\n",
        "    print(\"Formato de anotaciones no reconocido. Esperado intervalos o por frame.\")\n",
        "    return None\n",
        "\n",
        "ann_df = load_annotations(ANNOTATIONS_CSV)\n",
        "labels_per_frame = None\n",
        "if ann_df is not None:\n",
        "    labels_per_frame = align_annotations_per_frame(\n",
        "        ann_df, fps=max(video_info.fps, 1.0), frames=video_info.frame_count\n",
        "    )\n",
        "    if labels_per_frame is not None:\n",
        "        # recortar a los frames presentes en features_df\n",
        "        max_frame = features_df[\"frame\"].max()\n",
        "        labels_per_frame = labels_per_frame.iloc[: max_frame + 1]\n",
        "        label_aligned = labels_per_frame.reindex(features_df[\"frame\"].to_numpy(), fill_value=None).reset_index(drop=True)\n",
        "        features_df[\"label\"] = label_aligned\n",
        "        print(\"Distribución de clases:\")\n",
        "        print(features_df[\"label\"].value_counts(dropna=True))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxpYXA6hNol6"
      },
      "outputs": [],
      "source": [
        "# Exportar características a CSV\n",
        "out_path = Path(\"features.csv\")\n",
        "features_df.to_csv(out_path, index=False)\n",
        "print(\"Guardado:\", out_path.resolve())"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}